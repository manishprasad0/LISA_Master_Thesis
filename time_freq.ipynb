{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f42f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#%config InlineBackend.figure_format = 'retina'  # For sharper figures, but it takes more time\n",
    "import scipy as sp\n",
    "from copy import deepcopy \n",
    "\n",
    "from lisatools.utils.constants import *\n",
    "from lisatools.sensitivity  import SensitivityMatrix, AET1SensitivityMatrix, AE1SensitivityMatrix\n",
    "from lisatools.analysiscontainer import AnalysisContainer\n",
    "from lisatools.datacontainer import DataResidualArray\n",
    "\n",
    "from bbhx.waveforms.phenomhm import PhenomHMAmpPhase\n",
    "from bbhx.waveformbuild import BBHWaveformFD\n",
    "from bbhx.utils.interpolate import CubicSplineInterpolant\n",
    "\n",
    "import noise_generation as noise_generation\n",
    "from tools.LISASimulator import LISASimulator\n",
    "from tools.likelihood import get_dh, get_hh\n",
    "import tools.likelihood as likelihood\n",
    "\n",
    "from tools.time_freq_likelihood import TimeFreqLikelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb71d8f",
   "metadata": {},
   "source": [
    "Generate simulated LISA data using LISASimulator. Returns:\n",
    "1. Time domain data\n",
    "2. Frequency domain data\n",
    "3. Frequency array that can be used to generate templates using bbhx\n",
    "4. Time array if needed\n",
    "5. Sensitivity Matrix for inner product calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7306564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tobs = YRSID_SI\n",
    "dt = 5.\n",
    "include_T_channel = False # Set to True if you want to include the T channel in the simulation, otherwise only A and E channels will be included.\n",
    "\n",
    "wave_gen = BBHWaveformFD(amp_phase_kwargs=dict(run_phenomd=False))\n",
    "sim = LISASimulator(Tobs=Tobs, dt=dt, wave_gen=wave_gen, include_T_channel=include_T_channel)\n",
    "\n",
    "f_ref = 0.0\n",
    "phi_ref = 0.0\n",
    "m1 = 9e5\n",
    "m2 = 5e5\n",
    "a1 = 0.2\n",
    "a2 = 0.4\n",
    "dist = 10e3 * PC_SI * 1e6  # 3e3 in Mpc\n",
    "inc = np.pi/3\n",
    "beta = np.pi/4.\n",
    "lam = np.pi/5.\n",
    "psi = np.pi/6.\n",
    "t_ref = 0.5 * YRSID_SI  # in the SSB reference frame\n",
    "\n",
    "parameters = np.array([m1, m2, a1, a2, dist, phi_ref, f_ref, inc, lam, beta, psi, t_ref])\n",
    "\n",
    "modes = [(2,2), (2,1), (3,3), (3,2), (4,4), (4,3)]\n",
    "waveform_kwargs = dict(direct=False, fill=True, squeeze=False, length=1024)\n",
    "\n",
    "data_t, data_f, f_array, t_array, sens_mat = sim(seed = 42, parameters=parameters, modes=modes, waveform_kwargs=waveform_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86958b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = TimeFreqLikelihood(data_t=data_t, wave_gen=wave_gen, dt=dt)\n",
    "analysis.get_stft_of_data()\n",
    "analysis.calculate_time_frequency_likelihood(\n",
    "    m1*10,\n",
    "    m2, \n",
    "    a1,\n",
    "    a2,\n",
    "    dist, \n",
    "    phi_ref,\n",
    "    f_ref, \n",
    "    inc,\n",
    "    lam,\n",
    "    beta,\n",
    "    psi,\n",
    "    t_ref,\n",
    "    waveform_kwargs=dict(\n",
    "        length=1024, \n",
    "        combine=False,  # TODO: check this\n",
    "        direct=False,\n",
    "        fill=True,\n",
    "        squeeze=True,\n",
    "        freqs=f_array,\n",
    "        modes=modes\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e9b062",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = 0.08640623615147122\n",
    "m1_10 = -0.024209015459648226\n",
    "m1_1000 = -9.35790536288313e-10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbf3a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from eryn.ensemble import EnsembleSampler\n",
    "from eryn.prior import ProbDistContainer, uniform_dist\n",
    "from eryn.state import State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56cb0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper_likelihood(x, fixed_parameters, freqs, analysis, **kwargs):\n",
    "    all_parameters = np.zeros(12)\n",
    "    mT = x[0]\n",
    "    q = x[1]\n",
    "    all_parameters[0] = mT / (1 + q)\n",
    "    all_parameters[1] = mT * q / (1 + q)\n",
    "    all_parameters[5] = x[2]\n",
    "    all_parameters[-1] = x[3]\n",
    "\n",
    "    all_parameters[np.array([2, 3, 4, 6, 7, 8, 9, 10])] = fixed_parameters\n",
    "\n",
    "    ll = analysis.calculate_time_frequency_likelihood(\n",
    "        *all_parameters,\n",
    "        waveform_kwargs=dict(\n",
    "            length=1024, \n",
    "            combine=False,  # TODO: check this\n",
    "            direct=False,\n",
    "            fill=True,\n",
    "            squeeze=True,\n",
    "            freqs=freqs\n",
    "        ),\n",
    "    )\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b54d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear (for internal clearing of answers)\n",
    " \n",
    "priors = {\"mbh\": ProbDistContainer({\n",
    "    0: uniform_dist(9e5, 5e6),\n",
    "    1: uniform_dist(0.05, 0.999999),\n",
    "    2: uniform_dist(0.0, 2 * np.pi),\n",
    "    3: uniform_dist(0.0, Tobs + 24 * 3600.0),\n",
    "})}\n",
    "\n",
    "injection_params = np.array([\n",
    "    m1 + m2,\n",
    "    m2 / m1,\n",
    "    a1,\n",
    "    a2,\n",
    "    dist, \n",
    "    phi_ref,\n",
    "    f_ref, \n",
    "    inc,\n",
    "    lam,\n",
    "    beta,\n",
    "    psi,\n",
    "    t_ref\n",
    "])\n",
    "\n",
    "fixed_parameters = np.array([\n",
    "    a1,\n",
    "    a2,\n",
    "    dist, \n",
    "    f_ref, \n",
    "    inc,\n",
    "    lam,\n",
    "    beta,\n",
    "    psi,\n",
    "])\n",
    "\n",
    "periodic = {\"mbh\": {2: 2 * np.pi}}\n",
    "\n",
    "ntemps = 10\n",
    "nwalkers = 32\n",
    "ndims = {\"mbh\": 4}\n",
    "sampler = EnsembleSampler(\n",
    "    nwalkers,\n",
    "    ndims,\n",
    "    wrapper_likelihood,\n",
    "    priors,\n",
    "    args=(fixed_parameters, f_array, analysis),\n",
    "    branch_names=[\"mbh\"],\n",
    "    tempering_kwargs=dict(ntemps=ntemps),\n",
    "    nleaves_max=dict(mbh=1),\n",
    "    periodic=periodic\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2b9ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x[None] adds a new dimension at the front: Itâ€™s a standard trick to reshape arrays for broadcasting or stacking purposes.\n",
    " \n",
    "injection_params_sub = np.array([m1 + m2, m2 / m1, phi_ref, t_ref])\n",
    "start_params = injection_params_sub[None, None, None, :] * (1 + 1e-7 * np.random.randn(ntemps, nwalkers, 1, injection_params_sub.shape[0]))\n",
    "start_state = State({\"mbh\": start_params})\n",
    "sampler.compute_log_prior(start_state.branches_coords)\n",
    "sampler.run_mcmc(start_state, 10, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0707ccbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainconsumer import Chain, ChainConsumer, make_sample, Truth\n",
    "import pandas as pd\n",
    "samples = sampler.get_chain()[\"mbh\"][:, 0].reshape(-1, 4)\n",
    "df = pd.DataFrame(samples, columns=[\"mT\", \"q\", \"lam\", \"beta\"])\n",
    "c = ChainConsumer()\n",
    "c.add_chain(Chain(samples=df, name=\"An Example Contour\"))\n",
    "c.add_truth(Truth(location={\"mT\": injection_params_sub[0], \"q\": injection_params_sub[1], \"lam\": injection_params_sub[2], \"beta\": injection_params_sub[3]}))\n",
    "fig = c.plotter.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58e3a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,t,Zxx_data_A=sp.signal.stft(data_t[0], fs=1./dt, nperseg=15000)\n",
    "f,t,Zxx_data_E=sp.signal.stft(data_t[1], fs=1./dt, nperseg=15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d81756b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_parameters = np.array([m1, m2, a1, a2, dist, phi_ref, f_ref, inc, lam, beta, psi, t_ref], modes)\n",
    "parameters_new = deepcopy(parameters)\n",
    "\n",
    "# Modify the parameters as needed\n",
    "parameters_new[0] = 1.2 * m1  # Example: increase m1 by 20%\n",
    "parameters_new[1] = 0.8 * m2  # Example: decrease m2 by 20%\n",
    "\n",
    "template_f = wave_gen(*parameters_new,freqs=sim.freq, modes=modes, **waveform_kwargs)[0]\n",
    "template_f = template_f[:2] # remove T channel\n",
    "template_t = np.fft.irfft(template_f, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4cb03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,t,Zxx_A=sp.signal.stft(template_t[0], fs=1./dt, nperseg=15000)\n",
    "f,t,Zxx_E=sp.signal.stft(template_t[1], fs=1./dt, nperseg=15000)\n",
    "df = f[1] - f[0]\n",
    "f[0]=f[1]\n",
    "sens_mat_new = AE1SensitivityMatrix(f).sens_mat\n",
    "power_A = np.abs(Zxx_A)**2\n",
    "power_E = np.abs(Zxx_E)**2\n",
    "\n",
    "weighted_power_A = power_A / sens_mat_new[0][:, np.newaxis]\n",
    "weighted_power_E = power_E / sens_mat_new[1][:, np.newaxis]\n",
    "\n",
    "hh_A = np.sum(weighted_power_A)\n",
    "hh_E = np.sum(weighted_power_E)\n",
    "\n",
    "print((hh_A + hh_E)*4*df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8df331",
   "metadata": {},
   "outputs": [],
   "source": [
    "dh_total = 0.0\n",
    "for i in range(len(t)):\n",
    "    numerator_A = (np.abs(Zxx_A[:, i])**2)/sens_mat_new[0]\n",
    "    numerator_E = (np.abs(Zxx_E[:, i])**2)/sens_mat_new[1]\n",
    "    dh_A = np.sum(numerator_A) * df * 4\n",
    "    dh_E = np.sum(numerator_E) * df * 4\n",
    "    dh_total += dh_A + dh_E\n",
    "print(dh_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ad4677",
   "metadata": {},
   "outputs": [],
   "source": [
    "Zxx_data_A[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf5b640",
   "metadata": {},
   "outputs": [],
   "source": [
    "dh_total = 0.0\n",
    "for i in range(len(Zxx_data_A[0])):\n",
    "    numerator_A = np.real(Zxx_data_A[:, i].conj() * Zxx_A[:, i] / sens_mat_new[0])\n",
    "    numerator_E = np.real(Zxx_data_E[:, i].conj() * Zxx_E[:, i] / sens_mat_new[1])\n",
    "    dh_A = np.sum(numerator_A) * df * 4\n",
    "    dh_E = np.sum(numerator_E) * df * 4\n",
    "    dh_total += dh_A + dh_E\n",
    "print(dh_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77e932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element-wise multiply template and conjugate data, divide by sensitivity (freq axis)\n",
    "weighted_A = (Zxx_A * np.conj(Zxx_data_A)) / sens_mat_new[0][:, np.newaxis]  # shape (n_freq, n_time)\n",
    "weighted_E = (Zxx_E * np.conj(Zxx_data_E)) / sens_mat_new[1][:, np.newaxis]\n",
    "\n",
    "# Sum over freq and time axes and multiply by constants\n",
    "dh_total = 4 * df * np.sum(weighted_A.real + weighted_E.real)\n",
    "\n",
    "print(dh_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd3735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,2,3],[4,5,6],[7,8,9],[10,11,12]])\n",
    "y = np.array([10,10,100,1000])\n",
    "x/y[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d709b855",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_product_A = Zxx_A * np.conj(Zxx_A) / sens_mat_new[0][:, np.newaxis]\n",
    "inner_product_E = Zxx_E * np.conj(Zxx_E) / sens_mat_new[1][:, np.newaxis]\n",
    "dh_A = np.sum(inner_product_A, axis=-1)\n",
    "dh_E = np.sum(inner_product_E, axis=-1)\n",
    "inner_product = (np.real(dh_A) + np.real(dh_E)) * 4 * df\n",
    "print(inner_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8622f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dh_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56af0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "power = np.abs(Zxx_A)**2  # shape: (7501, 843)\n",
    "\n",
    "# Step 2: divide by the sensitivity matrix (broadcasts across time axis)\n",
    "weighted_power = power / sens_mat_A[:, np.newaxis]  # shape: (7501, 843)\n",
    "\n",
    "# Step 3: sum over all frequencies and times\n",
    "inner_product = np.sum(weighted_power)\n",
    "print(f\"Inner product: {inner_product}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81c8876",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.real(np.divide((Zxx[0].conj() * Zxx[0]) , np.array(AE1SensitivityMatrix(f)[0].T)[:, np.newaxis]))*4*df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b659fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = TimeFreqLikelihood()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b746fc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper_likelihood(variable_parameters, fixed_parameters, freqs, analysis, **kwargs):\n",
    "    all_parameters = np.zeros(12)\n",
    "    all_parameters[0] = variable_parameters[0]\n",
    "    all_parameters[1] = variable_parameters[1]\n",
    "    all_parameters[5] = variable_parameters[2]\n",
    "    all_parameters[-1] = variable_parameters[3]\n",
    "\n",
    "    all_parameters[np.array([2, 3, 4, 6, 7, 8, 9, 10])] = fixed_parameters\n",
    "\n",
    "    ll = analysis.calculate_signal_likelihood(\n",
    "        *all_parameters,\n",
    "        waveform_kwargs=dict(\n",
    "            length=1024, \n",
    "            combine=False,  # TODO: check this\n",
    "            direct=False,\n",
    "            fill=True,\n",
    "            squeeze=True,\n",
    "            freqs=freqs\n",
    "        ),\n",
    "        source_only=True\n",
    "        # data_arr_kwargs=dict(f_arr=freqs)\n",
    "    )\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0fbb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_from_lisatools = sim.SNR_optimal_lisatools()\n",
    "snr_my_code = sim.SNR_optimal()\n",
    "print(snr_from_lisatools, snr_my_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e621b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sim.signal_with_noise_f\n",
    "f_array = np.fft.rfftfreq(sim.signal_with_noise_t.shape[2])  # returns the correct frequency array for the signal with noise\n",
    "f_array[0] = f_array[1]  # avoid zero frequency\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f8b808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sim.df, len(sim.signal_with_noise_t[0,0])*sim.dt, sim.Tobs, sim.Tobs / sim.dt, sim.time.shape, sim.freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b951187",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0], template_f, sim.sens_mat.sens_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abac3a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = get_dh(data[0], template_f, sens_mat=sim.sens_mat, df=f_array[2] - f_array[1])\n",
    "hh = get_hh(template_f, sens_mat=sim.sens_mat, df=f_array[2] - f_array[1])\n",
    "dh/ np.sqrt(hh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lisa_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
